{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "scripts_dir = Path(\"../..\").joinpath(\"src\")\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.insert(0, scripts_dir.resolve().as_posix())\n",
    "from helpers.mapshaper import Mapshaper\n",
    "from helpers.tippcanoe import mbtileGeneration\n",
    "from helpers.mapbox_uploader import uploadToMapbox\n",
    "from helpers.settings import get_settings\n",
    "from helpers.file_handler import FileConventionHandler\n",
    "from helpers.utils import download_and_unzip_if_needed, writeReadGCP\n",
    "\n",
    "from data_commons.loader import load_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "mysettings = get_settings()\n",
    "prev_step = \"preprocess\"\n",
    "current_step = \"tiles\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### EEZs: Exclusive Economic Zones "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mambauser/data/eez/processed/eez_preprocess.zip\n",
      "/home/mambauser/data/eez/processed/preprocess\n"
     ]
    }
   ],
   "source": [
    "pipe = \"eez\"\n",
    "collection_name = f\"{pipe}_v11\"\n",
    "\n",
    "eez_dir = FileConventionHandler(pipe)\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(eez_dir, prev_step, mysettings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the translations file\n",
    "input_file = eez_dir.get_processed_step_path(prev_step).joinpath(\"eez_translation.csv\")\n",
    "\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=\"vizzuality_processed_data/eez/preprocess/eez_translation.csv\",\n",
    "    file=input_file,\n",
    "    operation=\"r\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/pyogrio/raw.py:709: RuntimeWarning: Value 212881389 of field AREA_KM2 of feature 281 not successfully written. Possibly due to too larger number with respect to field width\n",
      "  ogr_write(\n"
     ]
    }
   ],
   "source": [
    "# Add translations\n",
    "eez = gpd.read_file(eez_dir.get_step_fmt_file_path(prev_step, \"shp\").as_posix())\n",
    "translations = pd.read_csv(input_file).drop(columns=[\"GEONAME\", \"POL_TYPE\"])\n",
    "eez_translation = eez.merge(translations, on=\"MRGID\", how=\"left\")\n",
    "eez_translation.to_file(eez_dir.get_processed_step_path(prev_step).joinpath(\"eez_translation.shp\").as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "For layer 0, using name \"eez_tiles\"\n",
      "/home/mambauser/data/eez/processed/tiles/eez_tiles.json:10: Found ] at top level\n",
      "/home/mambauser/data/eez/processed/tiles/eez_tiles.json:55: Reached EOF without all containers being closed\n",
      "In JSON object {\"type\":\"FeatureCollection\",\"features\":[]}\n",
      "282 features, 62937109 bytes of geometry, 7882 bytes of separate metadata, 38990 bytes of string pool\n",
      "Choosing a maxzoom of -z0 for features about 2511227 feet (765422 meters) apart\n",
      "Choosing a maxzoom of -z9 for resolution of about 825 feet (251 meters) within features\n",
      "  99.9%  9/136/131  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mambauser/data/eez/processed/tiles/eez_tiles.mbtiles')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simplify the geometries\n",
    "Mapshaper(8).input([eez_dir.get_processed_step_path(prev_step).joinpath(\"eez_translation.shp\").as_posix()]).filter_fields(\n",
    "    fields=\",\".join([\"GEONAME\", \"GEONAME_ES\", \"GEONAME_FR\", \"POL_TYPE\", \"ISO_SOV1\", \"ISO_SOV2\", \"ISO_SOV3\"])\n",
    ").output(\n",
    "    eez_dir.get_step_fmt_file_path(current_step, \"json\").as_posix(), force=True, format=\"geojson\"\n",
    ").execute()\n",
    "\n",
    "# Generate mbtiles\n",
    "mbtileGeneration(eez_dir.get_step_fmt_file_path(current_step, \"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploadToMapbox(\n",
    "    eez_dir.get_processed_step_path(current_step).joinpath(f\"{collection_name}.mbtiles\"),\n",
    "    collection_name,\n",
    "    mysettings.MAPBOX_USER,\n",
    "    mysettings.MAPBOX_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### EEZs: wdpa Regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_name = \"regions\"\n",
    "\n",
    "# load the EEZ file & the regions file\n",
    "eez_data = gpd.read_file(eez_dir.get_step_fmt_file_path(prev_step, \"shp\").as_posix())\n",
    "regions_df = pd.DataFrame(\n",
    "    [\n",
    "        {\"region_id\": data[\"region_iso\"], \"location_id\": iso}\n",
    "        for data in load_regions().get(\"data\", [])\n",
    "        for iso in data[\"country_iso_3s\"]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# merge the two files\n",
    "gpd.GeoDataFrame(\n",
    "    pd.merge(\n",
    "        eez_data,\n",
    "        regions_df,\n",
    "        how=\"left\",\n",
    "        left_on=\"ISO_SOV1\",\n",
    "        right_on=\"location_id\",\n",
    "        sort=True,\n",
    "        copy=True,\n",
    "    ),\n",
    "    crs=eez_data.crs,\n",
    ").to_file(\n",
    "    filename=eez_dir.get_processed_step_path(prev_step)\n",
    "    .joinpath(f\"{pipe}_{prev_step}_{collection_name}.shp\")\n",
    "    .as_posix(),\n",
    "    driver=\"ESRI Shapefile\",\n",
    ")\n",
    "\n",
    "# dissolve by region_id\n",
    "\n",
    "Mapshaper(16).input(\n",
    "    [\n",
    "        eez_dir.get_processed_step_path(prev_step)\n",
    "        .joinpath(f\"{pipe}_{prev_step}_{collection_name}.shp\")\n",
    "        .as_posix()\n",
    "    ]\n",
    ").dissolve2(fields=\"region_id\").output(\n",
    "    eez_dir.get_processed_step_path(current_step).joinpath(f\"{collection_name}.json\").as_posix(),\n",
    "    force=True,\n",
    "    format=\"geojson\",\n",
    ").execute()\n",
    "\n",
    "# generate the mbtiles\n",
    "mbtileGeneration(eez_dir.get_processed_step_path(current_step).joinpath(f\"{collection_name}.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../data/eez/processed/tiles/regions.mbtiles to s3://tilestream-tilesets-production/97/_pending/ojc7oxn5cpu10yo0o9tsl1xlc/skytruth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking tileset to Mapbox: 100%|██████████| 100/100 [03:00<00:00,  1.81s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploadToMapbox(\n",
    "    eez_dir.get_processed_step_path(current_step).joinpath(f\"{collection_name}.mbtiles\"),\n",
    "    collection_name,\n",
    "    mysettings.MAPBOX_USER,\n",
    "    mysettings.MAPBOX_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MPAs: Marine Protected Areas from WDPA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mambauser/data/mpa/processed/mpa_preprocess.zip\n",
      "/home/mambauser/data/mpa/processed/preprocess\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m source_dir \u001b[38;5;241m=\u001b[39m FileConventionHandler(pipe)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Download the EEZ file && unzip it\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mdownload_and_unzip_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmysettings\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# simplify the geometries\u001b[39;00m\n\u001b[1;32m     10\u001b[0m Mapshaper(\u001b[38;5;241m16\u001b[39m)\u001b[38;5;241m.\u001b[39minput([source_dir\u001b[38;5;241m.\u001b[39mget_step_fmt_file_path(prev_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshp\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mas_posix()])\u001b[38;5;241m.\u001b[39mfilter_fields(\n\u001b[1;32m     11\u001b[0m     fields\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWDPAID,NAME,PA_DEF,GIS_M_AREA,PARENT_ISO\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m )\u001b[38;5;241m.\u001b[39mclean(allow_overlaps\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, rewind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39msimplify(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdp 10\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m keep-shapes planar\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mclean(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     source_dir\u001b[38;5;241m.\u001b[39mget_step_fmt_file_path(current_step, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mas_posix(), force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgeojson\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     16\u001b[0m )\u001b[38;5;241m.\u001b[39mexecute()\n",
      "File \u001b[0;32m~/src/helpers/utils.py:140\u001b[0m, in \u001b[0;36mdownload_and_unzip_if_needed\u001b[0;34m(file_handler, prev_step, mysettings)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m unzzipped_path\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m zip_path\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m--> 140\u001b[0m     \u001b[43mwriteReadGCP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmysettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGCS_KEYFILE_JSON\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbucket_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmysettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGCS_BUCKET\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mblob_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfile_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_remote_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_step\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzip_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43moperation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m shutil\u001b[38;5;241m.\u001b[39munpack_archive(zip_path, unzzipped_path\u001b[38;5;241m.\u001b[39mparent)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unzzipped_path\n",
      "File \u001b[0;32m~/src/helpers/utils.py:108\u001b[0m, in \u001b[0;36mwriteReadGCP\u001b[0;34m(credentials, bucket_name, blob_name, file, operation)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m operation \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m--> 108\u001b[0m         \u001b[43mblob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_to_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moperation must be \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/contextlib.py:81\u001b[0m, in \u001b[0;36mContextDecorator.__call__.<locals>.inner\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_recreate_cm():\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/google/cloud/storage/blob.py:1192\u001b[0m, in \u001b[0;36mBlob.download_to_file\u001b[0;34m(self, file_obj, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;129m@create_trace_span\u001b[39m(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStorage.Blob.downloadToFile\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_to_file\u001b[39m(\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1089\u001b[0m     retry\u001b[38;5;241m=\u001b[39mDEFAULT_RETRY,\n\u001b[1;32m   1090\u001b[0m ):\n\u001b[1;32m   1091\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Download the contents of this blob into a file-like object.\u001b[39;00m\n\u001b[1;32m   1092\u001b[0m \n\u001b[1;32m   1093\u001b[0m \u001b[38;5;124;03m    .. note::\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[38;5;124;03m    :raises: :class:`google.cloud.exceptions.NotFound`\u001b[39;00m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prep_and_do_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1193\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1196\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_etag_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_etag_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_etag_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_etag_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_generation_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_generation_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mif_metageneration_not_match\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/google/cloud/storage/blob.py:4420\u001b[0m, in \u001b[0;36mBlob._prep_and_do_download\u001b[0;34m(self, file_obj, client, start, end, raw_download, if_etag_match, if_etag_not_match, if_generation_match, if_generation_not_match, if_metageneration_match, if_metageneration_not_match, timeout, checksum, retry, command)\u001b[0m\n\u001b[1;32m   4417\u001b[0m transport \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39m_http\n\u001b[1;32m   4419\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4420\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_do_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4421\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfile_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdownload_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4424\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4425\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4426\u001b[0m \u001b[43m        \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4427\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4428\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4429\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchecksum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchecksum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4430\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4431\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4432\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m resumable_media\u001b[38;5;241m.\u001b[39mInvalidResponse \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m   4433\u001b[0m     _raise_from_invalid_response(exc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/google/cloud/storage/blob.py:1041\u001b[0m, in \u001b[0;36mBlob._do_download\u001b[0;34m(self, transport, file_obj, download_url, headers, start, end, raw_download, timeout, checksum, retry)\u001b[0m\n\u001b[1;32m   1035\u001b[0m     download\u001b[38;5;241m.\u001b[39m_retry_strategy \u001b[38;5;241m=\u001b[39m retry_strategy\n\u001b[1;32m   1036\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m create_trace_span(\n\u001b[1;32m   1037\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStorage.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdownload_class\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/consume\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1038\u001b[0m         attributes\u001b[38;5;241m=\u001b[39mextra_attributes,\n\u001b[1;32m   1039\u001b[0m         api_request\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1040\u001b[0m     ):\n\u001b[0;32m-> 1041\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mdownload\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1042\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extract_headers_from_download(response)\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/google/resumable_media/requests/download.py:263\u001b[0m, in \u001b[0;36mDownload.consume\u001b[0;34m(self, transport, timeout)\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_to_stream(result)\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m--> 263\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_request_helpers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_and_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretriable_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_status_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_strategy\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/google/resumable_media/requests/_request_helpers.py:155\u001b[0m, in \u001b[0;36mwait_and_retry\u001b[0;34m(func, get_status_code, retry_strategy)\u001b[0m\n\u001b[1;32m    153\u001b[0m error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _CONNECTION_ERROR_CLASSES \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    157\u001b[0m     error \u001b[38;5;241m=\u001b[39m e  \u001b[38;5;66;03m# Fall through to retry, if there are retries left.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/google/resumable_media/requests/download.py:259\u001b[0m, in \u001b[0;36mDownload.consume.<locals>.retriable_request\u001b[0;34m()\u001b[0m\n\u001b[1;32m    256\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bytes_downloaded \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_write_to_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/site-packages/google/resumable_media/requests/download.py:134\u001b[0m, in \u001b[0;36mDownload._write_to_stream\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stream\u001b[38;5;241m.\u001b[39mwrite(chunk)\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bytes_downloaded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk)\n\u001b[0;32m--> 134\u001b[0m         \u001b[43mlocal_checksum_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Don't validate the checksum for partial responses.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    138\u001b[0m     expected_checksum \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mPARTIAL_CONTENT\n\u001b[1;32m    140\u001b[0m ):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipe = \"mpa\"\n",
    "collection_name = \"mpas_wdpa\"\n",
    "\n",
    "source_dir = FileConventionHandler(pipe)\n",
    "\n",
    "# Download the EEZ file && unzip it\n",
    "download_and_unzip_if_needed(source_dir, prev_step, mysettings)\n",
    "\n",
    "# simplify the geometries\n",
    "Mapshaper(16).input([source_dir.get_step_fmt_file_path(prev_step, \"shp\").as_posix()]).filter_fields(\n",
    "    fields=\"WDPAID,NAME,PA_DEF,GIS_M_AREA,PARENT_ISO\"\n",
    ").clean(allow_overlaps=True, rewind=True).simplify(\"dp 10% keep-shapes planar\").clean(\n",
    "    allow_overlaps=True\n",
    ").output(\n",
    "    source_dir.get_step_fmt_file_path(current_step, \"json\").as_posix(), force=True, format=\"geojson\"\n",
    ").execute()\n",
    "\n",
    "# generate the mbtiles\n",
    "mbtileGeneration(source_dir.get_step_fmt_file_path(current_step, \"json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../data/mpa/processed/tiles/mpa_tiles.mbtiles to s3://tilestream-tilesets-production/de/_pending/yvng0dxxxru12eq9ye80350mc/skytruth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking tileset to Mapbox: 100%|██████████| 100/100 [02:34<00:00,  1.54s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploadToMapbox(\n",
    "    source_dir.get_step_fmt_file_path(current_step, \"mbtiles\"),\n",
    "    collection_name,\n",
    "    mysettings.MAPBOX_USER,\n",
    "    mysettings.MAPBOX_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### MPA Atlas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mambauser/data/mpaatlas/processed/mpaatlas_preprocess.zip\n",
      "/home/mambauser/data/mpaatlas/processed/preprocess\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allocating 50 GB of heap memory\n",
      "[clean] Retained 863 of 870 features\n",
      "[o] Wrote /home/mambauser/data/mpaatlas/processed/preprocess/mpaatlas_preprocess.json\n",
      "For layer 0, using name \"mpaatlas_preprocess\"\n",
      "/home/mambauser/data/mpaatlas/processed/preprocess/mpaatlas_preprocess.json:293: Reached EOF without all containers being closed\n",
      "In JSON object {\"type\":\"FeatureCollection\",\"features\":[]}\n",
      "/home/mambauser/data/mpaatlas/processed/preprocess/mpaatlas_preprocess.json:21: Found ] at top level\n",
      "863 features, 33449716 bytes of geometry, 29354 bytes of separate metadata, 53170 bytes of string pool\n",
      "Choosing a maxzoom of -z0 for features about 282844 feet (86211 meters) apart\n",
      "Choosing a maxzoom of -z12 for resolution of about 98 feet (30 meters) within features\n",
      "  99.9%  12/1004/2052  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mambauser/data/mpaatlas/processed/tiles/mpaatlas_tiles.mbtiles')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = \"mpaatlas\"\n",
    "collection_name = \"mpa_atlas\"\n",
    "\n",
    "source_dir = FileConventionHandler(pipe)\n",
    "# Download the data file && unzip it if needed\n",
    "download_and_unzip_if_needed(source_dir, prev_step, mysettings)\n",
    "\n",
    "# generate the mbtiles\n",
    "mbtileGeneration(\n",
    "    source_dir.get_step_fmt_file_path(prev_step, \"shp\"),\n",
    "    source_dir.get_step_fmt_file_path(current_step, \"mbtiles\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ../../data/mpaatlas/processed/tiles/mpaatlas_tiles.mbtiles to s3://tilestream-tilesets-production/32/_pending/4py3xz71znm1h1p9cr1v050mc/skytruth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Linking tileset to Mapbox: 100%|██████████| 100/100 [05:24<00:00,  3.25s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uploadToMapbox(\n",
    "    source_dir.get_step_fmt_file_path(current_step, \"mbtiles\"),\n",
    "    collection_name,\n",
    "    mysettings.MAPBOX_USER,\n",
    "    mysettings.MAPBOX_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Protected seas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = \"protectedseas\"\n",
    "collection_name = \"protected_seas\"\n",
    "\n",
    "pipe_dir = FileConventionHandler(pipe)\n",
    "input_file = pipe_dir.get_processed_step_path(prev_step).joinpath(\"ProtectedSeas_20240716.geojson\")\n",
    "output_file = pipe_dir.get_processed_step_path(current_step).joinpath(\"protectedseas_tiles.mbtiles\")\n",
    "\n",
    "\n",
    "# Download the protected seas file && unzip it\n",
    "writeReadGCP(\n",
    "    credentials=mysettings.GCS_KEYFILE_JSON,\n",
    "    bucket_name=mysettings.GCS_BUCKET,\n",
    "    blob_name=\"ProtectedSeas/ProtectedSeas_20240716.geojson\",\n",
    "    file=input_file,\n",
    "    operation=\"r\",\n",
    ")\n",
    "\n",
    "# Load the data\n",
    "protectedseas_layer = gpd.read_file(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Allocating 16 GB of heap memory\n",
      "[clean] Retained 6,741 of 6,741 features\n",
      "[simplify] Repaired 5,240 intersections; 629 intersections could not be repaired\n",
      "[clean] Retained 6,741 of 6,741 features\n",
      "[o] Wrote /home/mambauser/data/protectedseas/processed/preprocess/ProtectedSeas_20240716.geojson\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args='mapshaper-xl 16gb -i /home/mambauser/data/protectedseas/processed/preprocess/ProtectedSeas_20240716.geojson  -clean allow-overlaps rewind -simplify dp 10% keep-shapes planar -clean allow-overlaps -o /home/mambauser/data/protectedseas/processed/preprocess/ProtectedSeas_20240716.geojson force format=geojson', returncode=0)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simplify the geometries\n",
    "Mapshaper(16).input([input_file.as_posix()]).clean(\n",
    "    allow_overlaps=True, rewind=True\n",
    ").simplify(\"dp 10% keep-shapes planar\").clean(allow_overlaps=True).output(\n",
    "    input_file.as_posix(),\n",
    "    force=True,\n",
    "    format=\"geojson\",\n",
    ").execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/mambauser/data/protectedseas/processed/tiles/protectedseas_tiles.mbtiles')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mbtileGeneration(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rosetta error: failed to open elf at /lib64/ld-linux-x86-64.so.2\n",
      " Trace/breakpoint trap\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command 'aws s3 cp /home/mambauser/data/protectedseas/processed/tiles/protectedseas_tiles.mbtiles s3://tilestream-tilesets-production/71/_pending/lxene85xrno1vgk2b6c6350mc/skytruth --region us-east-1' returned non-zero exit status 133.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43muploadToMapbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprotected_seas\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmysettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAPBOX_USER\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmysettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMAPBOX_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/src/helpers/mapbox_uploader.py:21\u001b[0m, in \u001b[0;36muploadToMapbox\u001b[0;34m(source, display_name, username, token)\u001b[0m\n\u001b[1;32m     18\u001b[0m tileset_name \u001b[38;5;241m=\u001b[39m source\u001b[38;5;241m.\u001b[39mstem\n\u001b[1;32m     19\u001b[0m mapboxCredentials \u001b[38;5;241m=\u001b[39m getS3Credentials(username, token)\n\u001b[0;32m---> 21\u001b[0m upload_status \u001b[38;5;241m=\u001b[39m \u001b[43muploadToS3\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapboxCredentials\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(upload_status)\n\u001b[1;32m     23\u001b[0m result \u001b[38;5;241m=\u001b[39m linkToMapbox(\n\u001b[1;32m     24\u001b[0m     username, token, mapboxCredentials, tileset_name, display_name\n\u001b[1;32m     25\u001b[0m )\n",
      "File \u001b[0;32m~/src/helpers/mapbox_uploader.py:51\u001b[0m, in \u001b[0;36muploadToS3\u001b[0;34m(source, credentials)\u001b[0m\n\u001b[1;32m     49\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUploading to S3...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m setS3Credentials(credentials)\n\u001b[0;32m---> 51\u001b[0m status \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maws s3 cp \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43msource\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m s3://\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcredentials\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbucket\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcredentials\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mkey\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m --region us-east-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m status\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpload to S3 failed with status \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstatus\u001b[38;5;241m.\u001b[39mreturncode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.12/subprocess.py:571\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    570\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 571\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    572\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command 'aws s3 cp /home/mambauser/data/protectedseas/processed/tiles/protectedseas_tiles.mbtiles s3://tilestream-tilesets-production/71/_pending/lxene85xrno1vgk2b6c6350mc/skytruth --region us-east-1' returned non-zero exit status 133."
     ]
    }
   ],
   "source": [
    "uploadToMapbox(\n",
    "    output_file,\n",
    "    \"protected_seas\",\n",
    "    mysettings.MAPBOX_USER,\n",
    "    mysettings.MAPBOX_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Habitat layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add all the habitats layer processing\n",
    "habitat = mysettings.DATA_DIR.joinpath(\"habitat_intermediate\", \"layer\").resolve()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warm water corals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_water_corals = habitat.joinpath(\"warm_water_corals.mbtiles\").resolve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploadToMapbox(\n",
    "    warm_water_corals,\n",
    "    \"warm_water_corals\",\n",
    "    mysettings.MAPBOX_USER,\n",
    "    mysettings.MAPBOX_TOKEN,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contextual layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: we need to add the contextual layers upload here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
